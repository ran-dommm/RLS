{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "{'edges': 779, 'feat': 73}\n",
      "{'edges': 787, 'feat': 109}\n",
      "{'edges': 461, 'feat': 76}\n",
      "{'edges': 344, 'feat': 55}\n",
      "{'edges': 619, 'feat': 93}\n",
      "{'edges': 152, 'feat': 37}\n",
      "{'edges': 625, 'feat': 67}\n",
      "{'edges': 250, 'feat': 45}\n",
      "{'edges': 271, 'feat': 63}\n",
      "{'edges': 283, 'feat': 107}\n",
      "{'edges': 156, 'feat': 35}\n",
      "{'edges': 207, 'feat': 53}\n",
      "{'edges': 138, 'feat': 40}\n",
      "{'edges': 815, 'feat': 56}\n",
      "{'edges': 356, 'feat': 88}\n",
      "{'edges': 850, 'feat': 152}\n",
      "{'edges': 371, 'feat': 85}\n",
      "{'edges': 716, 'feat': 80}\n",
      "{'edges': 561, 'feat': 59}\n",
      "{'edges': 736, 'feat': 87}\n",
      "{'edges': 216, 'feat': 31}\n",
      "{'edges': 857, 'feat': 85}\n",
      "{'edges': 774, 'feat': 122}\n",
      "{'edges': 280, 'feat': 26}\n",
      "{'edges': 196, 'feat': 44}\n",
      "{'edges': 811, 'feat': 74}\n",
      "{'edges': 993, 'feat': 55}\n",
      "{'edges': 637, 'feat': 125}\n",
      "{'edges': 533, 'feat': 127}\n",
      "{'edges': 358, 'feat': 33}\n",
      "{'edges': 325, 'feat': 34}\n",
      "{'edges': 201, 'feat': 39}\n",
      "{'edges': 402, 'feat': 72}\n",
      "{'edges': 719, 'feat': 99}\n",
      "{'edges': 276, 'feat': 35}\n",
      "{'edges': 545, 'feat': 86}\n",
      "{'edges': 122, 'feat': 35}\n",
      "{'edges': 558, 'feat': 76}\n",
      "{'edges': 747, 'feat': 57}\n",
      "{'edges': 602, 'feat': 98}\n",
      "{'edges': 392, 'feat': 94}\n",
      "{'edges': 296, 'feat': 22}\n",
      "{'edges': 147, 'feat': 23}\n",
      "{'edges': 443, 'feat': 47}\n",
      "{'edges': 522, 'feat': 51}\n",
      "{'edges': 690, 'feat': 75}\n",
      "{'edges': 820, 'feat': 110}\n",
      "{'edges': 126, 'feat': 18}\n",
      "{'edges': 589, 'feat': 61}\n",
      "{'edges': 412, 'feat': 25}\n",
      "{'edges': 345, 'feat': 74}\n",
      "{'edges': 788, 'feat': 104}\n",
      "{'edges': 505, 'feat': 85}\n",
      "{'edges': 461, 'feat': 128}\n",
      "{'edges': 851, 'feat': 111}\n",
      "{'edges': 223, 'feat': 52}\n",
      "{'edges': 190, 'feat': 54}\n",
      "{'edges': 760, 'feat': 96}\n",
      "{'edges': 837, 'feat': 116}\n",
      "{'edges': 671, 'feat': 86}\n",
      "{'edges': 321, 'feat': 61}\n",
      "{'edges': 931, 'feat': 99}\n",
      "{'edges': 532, 'feat': 59}\n",
      "{'edges': 622, 'feat': 79}\n",
      "{'edges': 657, 'feat': 95}\n",
      "{'edges': 294, 'feat': 131}\n",
      "{'edges': 340, 'feat': 48}\n",
      "{'edges': 455, 'feat': 34}\n",
      "{'edges': 552, 'feat': 48}\n",
      "{'edges': 367, 'feat': 83}\n",
      "{'edges': 326, 'feat': 27}\n",
      "{'edges': 862, 'feat': 67}\n",
      "{'edges': 868, 'feat': 136}\n",
      "{'edges': 996, 'feat': 129}\n",
      "{'edges': 408, 'feat': 56}\n",
      "{'edges': 732, 'feat': 51}\n",
      "{'edges': 572, 'feat': 95}\n",
      "{'edges': 413, 'feat': 51}\n",
      "{'edges': 922, 'feat': 96}\n",
      "{'edges': 821, 'feat': 207}\n",
      "{'edges': 164, 'feat': 61}\n",
      "{'edges': 521, 'feat': 42}\n",
      "{'edges': 249, 'feat': 41}\n",
      "{'edges': 232, 'feat': 28}\n",
      "{'edges': 476, 'feat': 76}\n",
      "{'edges': 661, 'feat': 34}\n",
      "{'edges': 899, 'feat': 68}\n",
      "{'edges': 488, 'feat': 110}\n",
      "{'edges': 435, 'feat': 77}\n",
      "{'edges': 705, 'feat': 134}\n",
      "{'edges': 968, 'feat': 94}\n",
      "{'edges': 199, 'feat': 59}\n",
      "{'edges': 967, 'feat': 160}\n",
      "{'edges': 512, 'feat': 75}\n",
      "{'edges': 444, 'feat': 69}\n",
      "{'edges': 977, 'feat': 91}\n",
      "{'edges': 639, 'feat': 151}\n",
      "{'edges': 819, 'feat': 115}\n",
      "{'edges': 417, 'feat': 63}\n",
      "{'edges': 553, 'feat': 91}\n",
      "{'edges': 613, 'feat': 90}\n",
      "{'edges': 733, 'feat': 57}\n",
      "{'edges': 299, 'feat': 92}\n",
      "{'edges': 585, 'feat': 133}\n",
      "{'edges': 920, 'feat': 181}\n",
      "{'edges': 307, 'feat': 56}\n",
      "{'edges': 255, 'feat': 44}\n",
      "{'edges': 648, 'feat': 69}\n",
      "{'edges': 303, 'feat': 54}\n",
      "{'edges': 787, 'feat': 46}\n",
      "{'edges': 791, 'feat': 72}\n",
      "{'edges': 303, 'feat': 40}\n",
      "{'edges': 774, 'feat': 64}\n",
      "{'edges': 615, 'feat': 84}\n",
      "{'edges': 554, 'feat': 99}\n",
      "{'edges': 750, 'feat': 61}\n",
      "{'edges': 769, 'feat': 58}\n",
      "{'edges': 858, 'feat': 108}\n",
      "{'edges': 208, 'feat': 53}\n",
      "{'edges': 139, 'feat': 21}\n",
      "{'edges': 157, 'feat': 33}\n",
      "{'edges': 316, 'feat': 72}\n",
      "{'edges': 951, 'feat': 104}\n",
      "{'edges': 693, 'feat': 118}\n",
      "{'edges': 529, 'feat': 103}\n",
      "{'edges': 209, 'feat': 79}\n",
      "{'edges': 531, 'feat': 81}\n",
      "{'edges': 126, 'feat': 30}\n",
      "{'edges': 934, 'feat': 55}\n",
      "{'edges': 294, 'feat': 26}\n",
      "{'edges': 487, 'feat': 64}\n",
      "{'edges': 309, 'feat': 32}\n",
      "{'edges': 861, 'feat': 77}\n",
      "{'edges': 458, 'feat': 96}\n",
      "{'edges': 818, 'feat': 152}\n",
      "{'edges': 909, 'feat': 71}\n",
      "{'edges': 561, 'feat': 63}\n",
      "{'edges': 811, 'feat': 120}\n",
      "{'edges': 585, 'feat': 104}\n",
      "{'edges': 869, 'feat': 69}\n",
      "{'edges': 208, 'feat': 24}\n",
      "{'edges': 400, 'feat': 95}\n",
      "{'edges': 441, 'feat': 91}\n",
      "{'edges': 868, 'feat': 135}\n",
      "{'edges': 241, 'feat': 45}\n",
      "{'edges': 644, 'feat': 70}\n",
      "{'edges': 354, 'feat': 64}\n",
      "{'edges': 801, 'feat': 140}\n",
      "{'edges': 341, 'feat': 44}\n",
      "{'edges': 836, 'feat': 65}\n",
      "{'edges': 822, 'feat': 91}\n",
      "{'edges': 971, 'feat': 134}\n",
      "{'edges': 275, 'feat': 29}\n",
      "{'edges': 967, 'feat': 145}\n",
      "{'edges': 245, 'feat': 25}\n",
      "{'edges': 238, 'feat': 29}\n",
      "{'edges': 496, 'feat': 91}\n",
      "{'edges': 467, 'feat': 71}\n",
      "{'edges': 115, 'feat': 47}\n",
      "{'edges': 556, 'feat': 106}\n",
      "{'edges': 672, 'feat': 70}\n",
      "{'edges': 217, 'feat': 48}\n",
      "{'edges': 245, 'feat': 79}\n",
      "{'edges': 894, 'feat': 103}\n",
      "{'edges': 841, 'feat': 54}\n",
      "{'edges': 849, 'feat': 124}\n",
      "{'edges': 488, 'feat': 100}\n",
      "{'edges': 162, 'feat': 76}\n",
      "{'edges': 488, 'feat': 97}\n",
      "{'edges': 276, 'feat': 114}\n",
      "{'edges': 540, 'feat': 150}\n",
      "{'edges': 675, 'feat': 42}\n",
      "{'edges': 442, 'feat': 67}\n",
      "{'edges': 712, 'feat': 119}\n",
      "{'edges': 620, 'feat': 116}\n",
      "{'edges': 523, 'feat': 115}\n",
      "{'edges': 414, 'feat': 104}\n",
      "{'edges': 134, 'feat': 61}\n",
      "{'edges': 372, 'feat': 73}\n",
      "{'edges': 107, 'feat': 26}\n",
      "{'edges': 216, 'feat': 34}\n",
      "{'edges': 522, 'feat': 118}\n",
      "{'edges': 985, 'feat': 86}\n",
      "{'edges': 654, 'feat': 68}\n",
      "{'edges': 759, 'feat': 56}\n",
      "{'edges': 956, 'feat': 168}\n",
      "{'edges': 795, 'feat': 77}\n",
      "{'edges': 692, 'feat': 103}\n",
      "{'edges': 569, 'feat': 38}\n",
      "{'edges': 264, 'feat': 39}\n",
      "{'edges': 357, 'feat': 69}\n",
      "{'edges': 653, 'feat': 53}\n",
      "{'edges': 614, 'feat': 84}\n",
      "{'edges': 731, 'feat': 104}\n",
      "{'edges': 126, 'feat': 52}\n",
      "{'edges': 672, 'feat': 72}\n",
      "{'edges': 429, 'feat': 46}\n",
      "{'edges': 371, 'feat': 69}\n",
      "{'edges': 348, 'feat': 32}\n",
      "{'edges': 823, 'feat': 149}\n",
      "{'edges': 536, 'feat': 31}\n",
      "{'edges': 567, 'feat': 46}\n",
      "{'edges': 448, 'feat': 37}\n",
      "{'edges': 885, 'feat': 78}\n",
      "{'edges': 667, 'feat': 61}\n",
      "{'edges': 307, 'feat': 79}\n",
      "{'edges': 248, 'feat': 44}\n",
      "{'edges': 888, 'feat': 53}\n",
      "{'edges': 456, 'feat': 96}\n",
      "{'edges': 995, 'feat': 175}\n",
      "{'edges': 127, 'feat': 18}\n",
      "{'edges': 594, 'feat': 51}\n",
      "{'edges': 111, 'feat': 46}\n",
      "{'edges': 150, 'feat': 71}\n",
      "{'edges': 703, 'feat': 102}\n",
      "{'edges': 580, 'feat': 120}\n",
      "{'edges': 442, 'feat': 30}\n",
      "{'edges': 313, 'feat': 51}\n",
      "{'edges': 651, 'feat': 80}\n",
      "{'edges': 557, 'feat': 91}\n",
      "{'edges': 111, 'feat': 13}\n",
      "{'edges': 438, 'feat': 96}\n",
      "{'edges': 273, 'feat': 25}\n",
      "{'edges': 380, 'feat': 66}\n",
      "{'edges': 475, 'feat': 59}\n",
      "{'edges': 204, 'feat': 88}\n",
      "{'edges': 638, 'feat': 139}\n",
      "{'edges': 139, 'feat': 37}\n",
      "{'edges': 816, 'feat': 100}\n",
      "{'edges': 441, 'feat': 50}\n",
      "{'edges': 513, 'feat': 87}\n",
      "{'edges': 450, 'feat': 113}\n",
      "{'edges': 393, 'feat': 58}\n",
      "{'edges': 792, 'feat': 72}\n",
      "{'edges': 734, 'feat': 103}\n",
      "{'edges': 138, 'feat': 41}\n",
      "{'edges': 406, 'feat': 95}\n",
      "{'edges': 269, 'feat': 78}\n",
      "{'edges': 883, 'feat': 82}\n",
      "{'edges': 622, 'feat': 124}\n",
      "{'edges': 583, 'feat': 79}\n",
      "{'edges': 506, 'feat': 60}\n",
      "{'edges': 301, 'feat': 25}\n",
      "{'edges': 245, 'feat': 122}\n",
      "{'edges': 656, 'feat': 96}\n",
      "{'edges': 653, 'feat': 222}\n",
      "{'edges': 554, 'feat': 57}\n",
      "{'edges': 326, 'feat': 37}\n",
      "{'edges': 610, 'feat': 107}\n",
      "{'edges': 698, 'feat': 87}\n",
      "{'edges': 125, 'feat': 14}\n",
      "{'edges': 400, 'feat': 42}\n",
      "{'edges': 568, 'feat': 101}\n",
      "{'edges': 105, 'feat': 37}\n",
      "{'edges': 427, 'feat': 33}\n",
      "{'edges': 460, 'feat': 38}\n",
      "{'edges': 195, 'feat': 40}\n",
      "{'edges': 521, 'feat': 113}\n",
      "{'edges': 366, 'feat': 111}\n",
      "{'edges': 582, 'feat': 84}\n",
      "{'edges': 627, 'feat': 100}\n",
      "{'edges': 719, 'feat': 60}\n",
      "{'edges': 176, 'feat': 30}\n",
      "{'edges': 721, 'feat': 65}\n",
      "{'edges': 463, 'feat': 52}\n",
      "{'edges': 280, 'feat': 122}\n",
      "{'edges': 921, 'feat': 128}\n",
      "{'edges': 698, 'feat': 159}\n",
      "{'edges': 544, 'feat': 86}\n",
      "{'edges': 420, 'feat': 75}\n",
      "{'edges': 474, 'feat': 73}\n",
      "{'edges': 166, 'feat': 22}\n",
      "{'edges': 909, 'feat': 111}\n",
      "{'edges': 272, 'feat': 30}\n",
      "{'edges': 463, 'feat': 108}\n",
      "{'edges': 946, 'feat': 92}\n",
      "{'edges': 578, 'feat': 94}\n",
      "{'edges': 224, 'feat': 59}\n",
      "{'edges': 350, 'feat': 43}\n",
      "{'edges': 583, 'feat': 146}\n",
      "{'edges': 416, 'feat': 82}\n",
      "{'edges': 553, 'feat': 65}\n",
      "{'edges': 546, 'feat': 100}\n",
      "{'edges': 987, 'feat': 90}\n",
      "{'edges': 867, 'feat': 116}\n",
      "{'edges': 928, 'feat': 147}\n",
      "{'edges': 327, 'feat': 66}\n",
      "{'edges': 331, 'feat': 78}\n",
      "{'edges': 950, 'feat': 66}\n",
      "{'edges': 893, 'feat': 57}\n",
      "{'edges': 473, 'feat': 99}\n",
      "{'edges': 782, 'feat': 119}\n",
      "{'edges': 894, 'feat': 101}\n",
      "{'edges': 285, 'feat': 102}\n",
      "{'edges': 450, 'feat': 101}\n",
      "{'edges': 335, 'feat': 70}\n",
      "{'edges': 285, 'feat': 23}\n",
      "{'edges': 364, 'feat': 121}\n",
      "{'edges': 418, 'feat': 60}\n",
      "{'edges': 731, 'feat': 102}\n",
      "{'edges': 940, 'feat': 128}\n",
      "{'edges': 557, 'feat': 78}\n",
      "{'edges': 523, 'feat': 63}\n",
      "max_edge: 996\n",
      "max_feat: 222\n",
      "min_edge: 105\n",
      "min_feat: 13\n",
      "avg_edge: 527.1122112211222\n",
      "avg_feat: 77.36963696369637\n",
      "max_diameter: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "twitter_folder = \"twitter\"\n",
    "\n",
    "id_data = {}\n",
    "\n",
    "for file in os.listdir(twitter_folder):\n",
    "    if file.endswith(\".edges\") or file.endswith(\".feat\"):\n",
    "        # 获取文件名和扩展名\n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "\n",
    "        id = filename\n",
    "        if id not in id_data:\n",
    "            id_data[id] = {\"edges\": 0, \"feat\": 0}\n",
    "\n",
    "        file_path = os.path.join(twitter_folder, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "\n",
    "        if file_extension == \".edges\":\n",
    "            id_data[id][\"edges\"] = line_count\n",
    "        elif file_extension == \".feat\":\n",
    "            id_data[id][\"feat\"] = line_count\n",
    "\n",
    "selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 1e2 and data['edges'] < 1e3]\n",
    "print(len(selected_ids))\n",
    "for id in selected_ids:\n",
    "    print(id_data[id])\n",
    "\n",
    "# find max edge number and max feat number and avg edge number and avg feat number of selected_ids\n",
    "max_edge = 0\n",
    "max_feat = 0\n",
    "min_edge = 1e10\n",
    "min_feat = 1e10\n",
    "avg_edge = 0\n",
    "avg_feat = 0\n",
    "max_diameter = 0\n",
    "for id in selected_ids:\n",
    "    max_edge = max(max_edge, id_data[id][\"edges\"])\n",
    "    max_feat = max(max_feat, id_data[id][\"feat\"])\n",
    "    min_edge = min(min_edge, id_data[id][\"edges\"])\n",
    "    min_feat = min(min_feat, id_data[id][\"feat\"])\n",
    "    avg_edge += id_data[id][\"edges\"]\n",
    "    avg_feat += id_data[id][\"feat\"]\n",
    "    edges_file_path = f\"{twitter_folder}/{id}.edges\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "    with open(edges_file_path, 'r') as edges_file:\n",
    "        for line in edges_file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                follower = int(parts[0])\n",
    "                followee = int(parts[1])\n",
    "                G.add_edge(followee, follower)\n",
    "    \n",
    "    \n",
    "    G = nx.Graph(G.subgraph(max(nx.connected_components(G), key=len)))\n",
    "    max_diameter = max(max_diameter, nx.diameter(G))\n",
    "\n",
    "pickle.dump((selected_ids, max_feat+1, max_edge+1), open(\"t1he.pkl\", \"wb\"))\n",
    "print(\"max_edge:\", max_edge)\n",
    "print(\"max_feat:\", max_feat)\n",
    "print(\"min_edge:\", min_edge)\n",
    "print(\"min_feat:\", min_feat)\n",
    "print(\"avg_edge:\", avg_edge/len(selected_ids))\n",
    "print(\"avg_feat:\", avg_feat/len(selected_ids))\n",
    "print(\"max_diameter:\", max_diameter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 1e3 and data['edges'] < 8e3]\n",
    "# print((selected_ids))\n",
    "\n",
    "# max_edge = 0\n",
    "# max_feat = 0\n",
    "# min_edge = 1e10\n",
    "# min_feat = 1e10\n",
    "# avg_edge = 0\n",
    "# avg_feat = 0\n",
    "# max_diameter = 0\n",
    "# for id in selected_ids:\n",
    "#     max_edge = max(max_edge, id_data[id][\"edges\"])\n",
    "#     max_feat = max(max_feat, id_data[id][\"feat\"])\n",
    "#     min_edge = min(min_edge, id_data[id][\"edges\"])\n",
    "#     min_feat = min(min_feat, id_data[id][\"feat\"])\n",
    "#     avg_edge += id_data[id][\"edges\"]\n",
    "#     avg_feat += id_data[id][\"feat\"]\n",
    "#     edges_file_path = f\"{twitter_folder}/{id}.edges\"\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     with open(edges_file_path, 'r') as edges_file:\n",
    "#         for line in edges_file:\n",
    "#             parts = line.strip().split()\n",
    "#             if len(parts) == 2:\n",
    "#                 follower = int(parts[0])\n",
    "#                 followee = int(parts[1])\n",
    "#                 G.add_edge(followee, follower)\n",
    "    \n",
    "    \n",
    "#     G = nx.Graph(G.subgraph(max(nx.connected_components(G), key=len)))\n",
    "#     max_diameter = max(max_diameter, nx.diameter(G))\n",
    "\n",
    "# pickle.dump((selected_ids, max_feat+1, max_edge+1), open(\"t1ke.pkl\", \"wb\"))\n",
    "# print(\"max_edge:\", max_edge)\n",
    "# print(\"max_feat:\", max_feat)\n",
    "# print(\"min_edge:\", min_edge)\n",
    "# print(\"min_feat:\", min_feat)\n",
    "# print(\"avg_edge:\", avg_edge/len(selected_ids))\n",
    "# print(\"avg_feat:\", avg_feat/len(selected_ids))\n",
    "# print(\"max_diameter:\", max_diameter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 8e3 and data[\"feat\"] > 0 and data['edges'] < 5e4]\n",
    "# print(len(selected_ids))\n",
    "\n",
    "# max_edge = 0\n",
    "# max_feat = 0\n",
    "# min_edge = 1e10\n",
    "# min_feat = 1e10\n",
    "# avg_edge = 0\n",
    "# avg_feat = 0\n",
    "# max_diameter = 0\n",
    "# for id in selected_ids:\n",
    "#     max_edge = max(max_edge, id_data[id][\"edges\"])\n",
    "#     max_feat = max(max_feat, id_data[id][\"feat\"])\n",
    "#     min_edge = min(min_edge, id_data[id][\"edges\"])\n",
    "#     min_feat = min(min_feat, id_data[id][\"feat\"])\n",
    "#     avg_edge += id_data[id][\"edges\"]\n",
    "#     avg_feat += id_data[id][\"feat\"]\n",
    "#     edges_file_path = f\"{twitter_folder}/{id}.edges\"\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     with open(edges_file_path, 'r') as edges_file:\n",
    "#         for line in edges_file:\n",
    "#             parts = line.strip().split()\n",
    "#             if len(parts) == 2:\n",
    "#                 follower = int(parts[0])\n",
    "#                 followee = int(parts[1])\n",
    "#                 G.add_edge(followee, follower)\n",
    "    \n",
    "    \n",
    "#     G = nx.Graph(G.subgraph(max(nx.connected_components(G), key=len)))\n",
    "#     max_diameter = max(max_diameter, nx.diameter(G))\n",
    "\n",
    "# pickle.dump((selected_ids, max_feat+1, max_edge+1), open(\"t1we.pkl\", \"wb\"))\n",
    "# print(\"max_edge:\", max_edge)\n",
    "# print(\"max_feat:\", max_feat)\n",
    "# print(\"min_edge:\", min_edge)\n",
    "# print(\"min_feat:\", min_feat)\n",
    "# print(\"avg_edge:\", avg_edge/len(selected_ids))\n",
    "# print(\"avg_feat:\", avg_feat/len(selected_ids))\n",
    "# print(\"max_diameter:\", max_diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "max_edge: 60050\n",
      "max_feat: 1045\n",
      "min_edge: 292\n",
      "min_feat: 59\n",
      "avg_edge: 17017.4\n",
      "avg_feat: 416.7\n",
      "max_diameter: 11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "twitter_folder = \"facebook\"\n",
    "\n",
    "id_data = {}\n",
    "\n",
    "# 遍历文件夹中的所有文件\n",
    "for file in os.listdir(twitter_folder):\n",
    "    if file.endswith(\".edges\") or file.endswith(\".feat\"):\n",
    "        # 获取文件名和扩展名\n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "\n",
    "        id = filename\n",
    "        if id not in id_data:\n",
    "            id_data[id] = {\"edges\": 0, \"feat\": 0}\n",
    "\n",
    "        file_path = os.path.join(twitter_folder, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "\n",
    "        if file_extension == \".edges\":\n",
    "            id_data[id][\"edges\"] = line_count\n",
    "        elif file_extension == \".feat\":\n",
    "            id_data[id][\"feat\"] = line_count\n",
    "\n",
    "\n",
    "# selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 5e2 and data[\"feat\"] > 0 and data[\"edges\"] < 2e3]\n",
    "# for id in selected_ids:\n",
    "#     print(id_data[id])\n",
    "    \n",
    "# max_edge = 0\n",
    "# max_feat = 0\n",
    "# min_edge = 1e10\n",
    "# min_feat = 1e10\n",
    "# for id in selected_ids:\n",
    "#     max_edge = max(max_edge, id_data[id][\"edges\"])\n",
    "#     max_feat = max(max_feat, id_data[id][\"feat\"])\n",
    "#     min_edge = min(min_edge, id_data[id][\"edges\"])\n",
    "#     min_feat = min(min_feat, id_data[id][\"feat\"])\n",
    "\n",
    "\n",
    "# pickle.dump((selected_ids, max_feat+1, max_edge+1), open(\"f1ke.pkl\", \"wb\"))\n",
    "# print(\"max_edge:\", max_edge)\n",
    "# print(\"max_feat:\", max_feat)\n",
    "# print(\"min_edge:\", min_edge)\n",
    "# print(\"min_feat:\", min_feat)\n",
    "\n",
    "selected_ids = [id for id, data in id_data.items() if data[\"edges\"] < 9e4 and data[\"feat\"] > 0]\n",
    "print(len(selected_ids))\n",
    "\n",
    "max_edge = 0\n",
    "max_feat = 0\n",
    "min_edge = 1e10\n",
    "min_feat = 1e10\n",
    "avg_edge = 0\n",
    "avg_feat = 0\n",
    "max_diameter = 0\n",
    "for id in selected_ids:\n",
    "    max_edge = max(max_edge, id_data[id][\"edges\"])\n",
    "    max_feat = max(max_feat, id_data[id][\"feat\"])\n",
    "    min_edge = min(min_edge, id_data[id][\"edges\"])\n",
    "    min_feat = min(min_feat, id_data[id][\"feat\"])\n",
    "    avg_edge += id_data[id][\"edges\"]\n",
    "    avg_feat += id_data[id][\"feat\"]\n",
    "    edges_file_path = f\"{twitter_folder}/{id}.edges\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "    with open(edges_file_path, 'r') as edges_file:\n",
    "        for line in edges_file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                follower = int(parts[0])\n",
    "                followee = int(parts[1])\n",
    "                G.add_edge(followee, follower)\n",
    "    \n",
    "    \n",
    "    G = nx.Graph(G.subgraph(max(nx.connected_components(G), key=len)))\n",
    "    max_diameter = max(max_diameter, nx.diameter(G))\n",
    "\n",
    "pickle.dump((selected_ids, max_feat+1, max_edge+1), open(\"t1ke.pkl\", \"wb\"))\n",
    "print(\"max_edge:\", max_edge)\n",
    "print(\"max_feat:\", max_feat)\n",
    "print(\"min_edge:\", min_edge)\n",
    "print(\"min_feat:\", min_feat)\n",
    "print(\"avg_edge:\", avg_edge/len(selected_ids))\n",
    "print(\"avg_feat:\", avg_feat/len(selected_ids))\n",
    "print(\"max_diameter:\", max_diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edges': 16043, 'feat': 657}\n",
      "{'edges': 10297, 'feat': 334}\n",
      "{'edges': 13119, 'feat': 510}\n",
      "{'edges': 18179, 'feat': 574}\n",
      "{'edges': 13800, 'feat': 327}\n",
      "{'edges': 14057, 'feat': 583}\n",
      "{'edges': 10111, 'feat': 773}\n",
      "{'edges': 13066, 'feat': 633}\n",
      "{'edges': 15502, 'feat': 503}\n",
      "{'edges': 12341, 'feat': 352}\n",
      "{'edges': 15148, 'feat': 457}\n",
      "{'edges': 19847, 'feat': 531}\n",
      "{'edges': 11716, 'feat': 325}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "twitter_folder = \"gplus\"\n",
    "\n",
    "id_data = {}\n",
    "\n",
    "# 遍历文件夹中的所有文件\n",
    "for file in os.listdir(twitter_folder):\n",
    "    if file.endswith(\".edges\") or file.endswith(\".feat\"):\n",
    "        # 获取文件名和扩展名\n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "\n",
    "        id = filename\n",
    "        if id not in id_data:\n",
    "            id_data[id] = {\"edges\": 0, \"feat\": 0}\n",
    "\n",
    "        file_path = os.path.join(twitter_folder, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "\n",
    "        if file_extension == \".edges\":\n",
    "            id_data[id][\"edges\"] = line_count\n",
    "        elif file_extension == \".feat\":\n",
    "            id_data[id][\"feat\"] = line_count\n",
    "\n",
    "print(id_data)\n",
    "selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 5e2 and data[\"feat\"] > 0 and data[\"edges\"] < 5e3]\n",
    "for id in selected_ids:\n",
    "    print(id_data[id])\n",
    "pickle.dump(selected_ids, open(\"g1ke.pkl\", \"wb\"))\n",
    "\n",
    "selected_ids = [id for id, data in id_data.items() if data[\"edges\"] > 1e4 and data[\"feat\"] > 0 and data[\"edges\"] < 2e4]\n",
    "for id in selected_ids:\n",
    "    print(id_data[id])\n",
    "pickle.dump(selected_ids, open(\"g1we.pkl\", \"wb\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.9.0-py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
